{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-06-15T17:43:15.464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --quiet \"pymupdf>=1.18.19\"\n!pip install --quiet \"pdf2image\"\n!pip install --quiet \"pytesseract\"\n!pip install --quiet \"pillow\"\n!pip install --quiet \"opencv-python\"\n!pip install --quiet \"pandas\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T17:43:27.669513Z","iopub.execute_input":"2025-06-15T17:43:27.670095Z","iopub.status.idle":"2025-06-15T17:47:03.302126Z","shell.execute_reply.started":"2025-06-15T17:43:27.670069Z","shell.execute_reply":"2025-06-15T17:47:03.300716Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78ee297bb050>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78ee297ac110>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78ee297c0bd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78ee297c2e10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x78ee297997d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pymupdf>=1.18.19 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pymupdf>=1.18.19\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --quiet \"pymupdf==1.22.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T17:56:53.473429Z","iopub.execute_input":"2025-06-15T17:56:53.473791Z","iopub.status.idle":"2025-06-15T18:00:14.416438Z","shell.execute_reply.started":"2025-06-15T17:56:53.473762Z","shell.execute_reply":"2025-06-15T18:00:14.415580Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bad57d760d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bad5649bfd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bad564a8210>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bad564aa890>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bad564a5f90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/pymupdf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pymupdf==1.22.0 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pymupdf==1.22.0\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!apt-get -y install poppler-utils  # Required by pdf2image\n!pip install --quiet pdf2image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:02:32.477117Z","iopub.execute_input":"2025-06-15T18:02:32.477417Z","iopub.status.idle":"2025-06-15T18:11:41.750517Z","shell.execute_reply.started":"2025-06-15T18:02:32.477394Z","shell.execute_reply":"2025-06-15T18:11:41.749487Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  libpoppler-dev libpoppler-private-dev libpoppler118\nThe following NEW packages will be installed:\n  poppler-utils\nThe following packages will be upgraded:\n  libpoppler-dev libpoppler-private-dev libpoppler118\n3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.\nNeed to get 1,462 kB of archives.\nAfter this operation, 700 kB of additional disk space will be used.\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nErr:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nErr:2 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nErr:3 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nErr:4 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler-private-dev_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler-dev_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler118_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# =============================\n# STEP 2: Imports\n# =============================\nimport os\nimport glob\nimport torch\nimport pandas as pd\nfrom PIL import Image\nfrom pdf2image import convert_from_path\nimport pytesseract\nfrom transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:12:21.797093Z","iopub.execute_input":"2025-06-15T18:12:21.797925Z","iopub.status.idle":"2025-06-15T18:12:44.629112Z","shell.execute_reply.started":"2025-06-15T18:12:21.797887Z","shell.execute_reply":"2025-06-15T18:12:44.628458Z"}},"outputs":[{"name":"stderr","text":"2025-06-15 18:12:32.638954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750011152.874496     312 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750011152.943374     312 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# =============================\n# STEP 3: InvoiceOCRParser Class\n# =============================\nclass InvoiceOCRParser:\n    def __init__(self,\n                 model_dir: str,\n                 processor_dir: str,\n                 label_map: dict = None,\n                 device: str = None):\n        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n        self.processor = LayoutLMv3Processor.from_pretrained(processor_dir, local_files_only=True)\n        self.model = LayoutLMv3ForTokenClassification.from_pretrained(model_dir, local_files_only=True)\n        self.model.to(self.device)\n        self.model.eval()\n\n        self.label_list = label_map or ['O', 'B-INVOICE_ID', 'I-INVOICE_ID',\n                                        'B-VENDOR', 'I-VENDOR',\n                                        'B-DATE', 'I-DATE',\n                                        'B-LINE_ITEM', 'I-LINE_ITEM',\n                                        'B-TAX', 'I-TAX',\n                                        'B-TOTAL', 'I-TOTAL']\n\n    def _pdf_to_images(self, pdf_path):\n        return convert_from_path(pdf_path, dpi=300)\n\n    def _load_images_from_folder(self, folder_path):\n        file_list = glob.glob(os.path.join(folder_path, \"*\"))\n        result = []\n        for file_path in file_list:\n            ext = file_path.lower().split('.')[-1]\n            if ext in ['jpg', 'jpeg', 'png']:\n                pil_img = Image.open(file_path).convert(\"RGB\")\n                result.append((os.path.basename(file_path), [pil_img]))\n            elif ext == 'pdf':\n                try:\n                    imgs = self._pdf_to_images(file_path)\n                    result.append((os.path.basename(file_path), imgs))\n                except Exception as e:\n                    print(f\"Could not parse PDF {file_path}: {e}\")\n        return result\n\n    def _image_to_words_boxes(self, image):\n        ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n        words, boxes = [], []\n        for i, word in enumerate(ocr_data['text']):\n            if word.strip() == \"\" or int(ocr_data['conf'][i]) < 0:\n                continue\n            x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n            words.append(word)\n            boxes.append([x, y, x + w, y + h])\n        return words, boxes\n\n    def _normalize_boxes(self, boxes, width, height):\n        norm = []\n        for box in boxes:\n            x0, y0, x1, y1 = box\n            norm.append([\n                int(1000 * x0 / width),\n                int(1000 * y0 / height),\n                int(1000 * x1 / width),\n                int(1000 * y1 / height)\n            ])\n        return norm\n\n    def _predict_tokens(self, words, boxes, image):\n        encoding = self.processor(\n            image, words, boxes=boxes, return_tensors=\"pt\", truncation=True,\n            max_length=512, padding=\"max_length\", return_attention_mask=True\n        )\n        encoding = {k: v.to(self.device) for k, v in encoding.items()}\n        with torch.no_grad():\n            outputs = self.model(**encoding).logits\n            probs = outputs.softmax(dim=-1)\n            preds = torch.argmax(probs, dim=-1).squeeze().tolist()\n        tokens = self.processor.tokenizer.convert_ids_to_tokens(encoding['input_ids'].squeeze())\n        labels = [self.label_list[p] if p < len(self.label_list) else 'O' for p in preds]\n        word_ids = encoding.get('word_ids') or self.processor.tokenizer(\n            words, boxes=boxes, add_special_tokens=True, padding='max_length',\n            truncation=True, max_length=512\n        ).word_ids()\n        out = []\n        last_word = None\n        for i, (label, tok, word_idx) in enumerate(zip(labels, tokens, word_ids)):\n            if word_idx is not None and word_idx != last_word:\n                last_word = word_idx\n                out.append((label, words[word_idx], boxes[word_idx]))\n        return out\n\n    def _extract_fields(self, label_word_box_tuples):\n        data = {\n            'InvoiceID': '',\n            'Vendor': '',\n            'Date': '',\n            'LineItems': [],\n            'Tax': '',\n            'Total': ''\n        }\n        current_field = None\n        field_buffer = {k: [] for k in ['INVOICE_ID', 'VENDOR', 'DATE', 'LINE_ITEM', 'TAX', 'TOTAL']}\n        for label, word, _ in label_word_box_tuples:\n            if label.startswith('B-'):\n                current_field = label[2:]\n                field_buffer[current_field].append(word)\n            elif label.startswith('I-') and current_field:\n                field_buffer[current_field].append(word)\n            else:\n                current_field = None\n        data['InvoiceID'] = ' '.join(field_buffer['INVOICE_ID']).strip()\n        data['Vendor'] = ' '.join(field_buffer['VENDOR']).strip()\n        data['Date'] = ' '.join(field_buffer['DATE']).strip()\n        data['Tax'] = ' '.join(field_buffer['TAX']).strip()\n        data['Total'] = ' '.join(field_buffer['TOTAL']).strip()\n        raw_lis = ' '.join(field_buffer['LINE_ITEM']).strip()\n        data['LineItems'] = [raw_lis] if raw_lis else []\n        return data\n\n    def process_folder(self, folder_path, display_log=True):\n        image_list = self._load_images_from_folder(folder_path)\n        results = []\n        for filename, images in image_list:\n            for page_no, img in enumerate(images):\n                words, boxes = self._image_to_words_boxes(img)\n                if not words:\n                    if display_log:\n                        print(f\"Could not OCR {filename} page {page_no + 1}, skipping.\")\n                    continue\n                norm_boxes = self._normalize_boxes(boxes, img.width, img.height)\n                label_word_box_tuples = self._predict_tokens(words, norm_boxes, img)\n                parsed = self._extract_fields(label_word_box_tuples)\n                result_row = dict(File=filename, Page=page_no + 1)\n                result_row.update(parsed)\n                results.append(result_row)\n                if display_log:\n                    print(f\"Parsed {filename} (page {page_no + 1}): {parsed}\")\n        return pd.DataFrame(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:15:06.231222Z","iopub.execute_input":"2025-06-15T18:15:06.231518Z","iopub.status.idle":"2025-06-15T18:15:06.249378Z","shell.execute_reply.started":"2025-06-15T18:15:06.231495Z","shell.execute_reply":"2025-06-15T18:15:06.248793Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!apt-get -y install poppler-utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:23:43.516491Z","iopub.execute_input":"2025-06-15T18:23:43.517364Z","iopub.status.idle":"2025-06-15T18:32:49.840661Z","shell.execute_reply.started":"2025-06-15T18:23:43.517339Z","shell.execute_reply":"2025-06-15T18:32:49.839829Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  libpoppler-dev libpoppler-private-dev libpoppler118\nThe following NEW packages will be installed:\n  poppler-utils\nThe following packages will be upgraded:\n  libpoppler-dev libpoppler-private-dev libpoppler118\n3 upgraded, 1 newly installed, 0 to remove and 84 not upgraded.\nNeed to get 1,462 kB of archives.\nAfter this operation, 700 kB of additional disk space will be used.\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nIgn:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\nIgn:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\nErr:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nIgn:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\nErr:2 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nIgn:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\nErr:3 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nErr:4 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8\n  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler-private-dev_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler-dev_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/libpoppler118_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.8_amd64.deb  Temporary failure resolving 'archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install -q transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:49:25.239269Z","iopub.execute_input":"2025-06-15T18:49:25.240092Z","iopub.status.idle":"2025-06-15T18:49:28.473473Z","shell.execute_reply.started":"2025-06-15T18:49:25.240059Z","shell.execute_reply":"2025-06-15T18:49:28.472649Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import AutoModel, AutoProcessor\n\n# Download model and processor from Hugging Face\nmodel = AutoModel.from_pretrained(\"microsoft/layoutlmv3-base\")\nprocessor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\")\n\n# Save them locally\nmodel.save_pretrained(\"layoutlmv3-base\")\nprocessor.save_pretrained(\"layoutlmv3-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:59:47.512083Z","iopub.execute_input":"2025-06-15T18:59:47.512392Z","iopub.status.idle":"2025-06-15T18:59:57.797308Z","shell.execute_reply.started":"2025-06-15T18:59:47.512371Z","shell.execute_reply":"2025-06-15T18:59:57.796385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710070253e8b425396e3f7d4c55145f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d0f96e9f9040ffb543697d8a91a073"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7188c507657240c29924d9ce23c5ca95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9934ec58a694d95963a84e931a399be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19b69bfd85b4af9bc28cdf245aa3e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a11a37936794fad8811616cc64af635"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"!zip -r layoutlmv3-base.zip layoutlmv3-base","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T19:02:05.422465Z","iopub.execute_input":"2025-06-15T19:02:05.423207Z","iopub.status.idle":"2025-06-15T19:02:32.140859Z","shell.execute_reply.started":"2025-06-15T19:02:05.423185Z","shell.execute_reply":"2025-06-15T19:02:32.139896Z"}},"outputs":[{"name":"stdout","text":"  adding: layoutlmv3-base/ (stored 0%)\n  adding: layoutlmv3-base/preprocessor_config.json (deflated 50%)\n  adding: layoutlmv3-base/config.json (deflated 56%)\n  adding: layoutlmv3-base/merges.txt (deflated 53%)\n  adding: layoutlmv3-base/tokenizer_config.json (deflated 75%)\n  adding: layoutlmv3-base/tokenizer.json (deflated 82%)\n  adding: layoutlmv3-base/special_tokens_map.json (deflated 85%)\n  adding: layoutlmv3-base/vocab.json (deflated 59%)\n  adding: layoutlmv3-base/model.safetensors (deflated 7%)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import os\nos.listdir()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T19:04:48.369885Z","iopub.execute_input":"2025-06-15T19:04:48.370210Z","iopub.status.idle":"2025-06-15T19:04:48.376671Z","shell.execute_reply.started":"2025-06-15T19:04:48.370185Z","shell.execute_reply":"2025-06-15T19:04:48.375919Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['layoutlmv3-base', '.virtual_documents', 'layoutlmv3-base.zip']"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Replace this with your actual parser class implementation if needed\nparser = InvoiceOCRParser(\n    model_dir='/kaggle/working/layoutlmv3-base',\n    processor_dir='/kaggle/working/layoutlmv3-base',\n)\n\n# Run inference on the folder of images\ninvoice_df = parser.process_folder('/kaggle/input/invoice_images/')  # Replace with your dataset\ndisplay(invoice_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T19:09:23.650044Z","iopub.execute_input":"2025-06-15T19:09:23.650911Z","iopub.status.idle":"2025-06-15T19:09:24.459920Z","shell.execute_reply.started":"2025-06-15T19:09:23.650879Z","shell.execute_reply":"2025-06-15T19:09:24.459178Z"}},"outputs":[{"name":"stderr","text":"Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at /kaggle/working/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Empty DataFrame\nColumns: []\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}